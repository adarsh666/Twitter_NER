{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13868363-d70f-46f8-8c2d-3404a0fb3dee",
   "metadata": {},
   "source": [
    "# Twitter NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ec53d-1fe1-43d2-8006-fbec218188c9",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "### Twitter is a microblogging and social networking service on which users post and interact with messages known as \"tweets\". Every second, on average, around 6,000 tweets are tweeted on Twitter, corresponding to over 350,000 tweets sent per minute, 500 million tweets per day.\n",
    "### Task is to tag and analyze tweets for better understanding of the trends and topics without being dependent on the hashtags that the users use. Many users do not use hashtags or sometimes use wrong or mis-spelled tags, so they want to completely remove this problem and create a system of recognizing important content of the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5bfe4026-119d-4bcd-9318-5ec98bf6f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Model\n",
    "#from tensorflow.keras.layers import \n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
    "\n",
    "from distutils.version import LooseVersion as LV\n",
    "from keras import __version__\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f4a8a3d-2bcd-475b-9651-1a5d761fb169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train file\n",
    "in_file = 'wnut 16.txt.conll' \n",
    "count = 1\n",
    "sentence = \"sentence\" + str(count)\n",
    "\n",
    "with open(in_file) as f:\n",
    "    sent, word, tag = [], [], []\n",
    "    for line in f.readlines():\n",
    "        sp = line.strip().split('\\t')\n",
    "        if len(sp) == 1:\n",
    "            count +=1\n",
    "            sentence = \"sentence\" + str(count)\n",
    "        elif len(sp) == 2:\n",
    "            sent.append(sentence)\n",
    "            word.append(sp[0].lower())\n",
    "            tag.append(sp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e02a397e-e2eb-4efd-810b-494a706f4819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46469\n",
      "46469\n",
      "46469\n"
     ]
    }
   ],
   "source": [
    "print(len(sent))\n",
    "print(len(word))\n",
    "print(len(tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "966998b8-b4ab-474d-baf0-35a3e692f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = 'wnut 16test.txt.conll' \n",
    "count = 1\n",
    "sentence = \"sentence\" + str(count)\n",
    "\n",
    "with open(in_file,encoding=\"utf8\") as f:\n",
    "    test_sent, test_word, test_tag = [], [], []\n",
    "    for line in f.readlines():\n",
    "        sp = line.strip().split('\\t')\n",
    "        if len(sp) == 1:\n",
    "            count +=1\n",
    "            sentence = \"sentence\" + str(count)\n",
    "        elif len(sp) == 2:\n",
    "            test_sent.append(sentence)\n",
    "            test_word.append(sp[0].lower())\n",
    "            test_tag.append(sp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "364a0bd5-6941-46e4-83d5-9b4abcbe77bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61908\n",
      "61908\n",
      "61908\n"
     ]
    }
   ],
   "source": [
    "print(len(test_sent))\n",
    "print(len(test_sent))\n",
    "print(len(test_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dda302dc-965d-4272-92d1-52e45721ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "data_dict = {'sentence' : sent, 'word' : word, 'tag' : tag}\n",
    "data = pd.DataFrame.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "73886759-fb59-4c53-853f-72f06eb35ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_data_dict = {'sentence' : test_sent, 'word' : test_word, 'tag' : test_tag}\n",
    "test_data = pd.DataFrame.from_dict(test_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e6180bf-e387-4d01-bc4d-5edad07be1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46464</th>\n",
       "      <td>sentence2394</td>\n",
       "      <td>whatchu</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46465</th>\n",
       "      <td>sentence2394</td>\n",
       "      <td>got</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46466</th>\n",
       "      <td>sentence2394</td>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46467</th>\n",
       "      <td>sentence2394</td>\n",
       "      <td>me</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46468</th>\n",
       "      <td>sentence2394</td>\n",
       "      <td>@kanyewest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentence        word tag\n",
       "46464  sentence2394     whatchu   O\n",
       "46465  sentence2394         got   O\n",
       "46466  sentence2394         for   O\n",
       "46467  sentence2394          me   O\n",
       "46468  sentence2394  @kanyewest   O"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b04c1c35-a547-4bd7-a88d-86eaf411acdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>@sammielynnsmom</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>@tg10781</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>they</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>will</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>be</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>all</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>done</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>by</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>sunday</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>trust</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>me</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>*wink*</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence             word tag\n",
       "0   sentence1  @sammielynnsmom   O\n",
       "1   sentence1         @tg10781   O\n",
       "2   sentence1             they   O\n",
       "3   sentence1             will   O\n",
       "4   sentence1               be   O\n",
       "5   sentence1              all   O\n",
       "6   sentence1             done   O\n",
       "7   sentence1               by   O\n",
       "8   sentence1           sunday   O\n",
       "9   sentence1            trust   O\n",
       "10  sentence1               me   O\n",
       "11  sentence1           *wink*   O"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['sentence']=='sentence1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a185bbc8-f9f9-4ac1-86f8-86a5f97e2a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags: 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "O                44007\n",
       "B-person           449\n",
       "I-other            320\n",
       "B-geo-loc          276\n",
       "B-other            225\n",
       "I-person           215\n",
       "B-company          171\n",
       "I-facility         105\n",
       "B-facility         104\n",
       "B-product           97\n",
       "I-product           80\n",
       "I-musicartist       61\n",
       "B-musicartist       55\n",
       "B-sportsteam        51\n",
       "I-geo-loc           49\n",
       "I-movie             46\n",
       "I-company           36\n",
       "B-movie             34\n",
       "B-tvshow            34\n",
       "I-tvshow            31\n",
       "I-sportsteam        23\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of tags: {}\".format(len(data.tag.unique())))\n",
    "frequencies = data.tag.value_counts()\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0019a512-36fd-440a-af29-189543c87109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd8e9642-7388-4c05-89cf-f9de1521aa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f8dd6e0-e46d-47bf-aa0c-cb259be44501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different words:\t21935\n",
      "Number of sentences:\t2394\n",
      "Number of different tags:\t21\n",
      "List of different tags:\t{'I-company', 'I-sportsteam', 'I-facility', 'B-geo-loc', 'I-tvshow', 'B-person', 'B-musicartist', 'B-company', 'B-other', 'O', 'I-geo-loc', 'B-facility', 'I-other', 'B-movie', 'B-product', 'I-musicartist', 'B-sportsteam', 'B-tvshow', 'I-movie', 'I-person', 'I-product'}\n"
     ]
    }
   ],
   "source": [
    "#Get the complete list of words\n",
    "words = list(set(data[\"word\"].values))\n",
    "test_words = list(set(test_data[\"word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "words = list(set(words + test_words))\n",
    "#Count the size of the dictionary, after adding a special token ENDPAD that\n",
    "#will be used to pad sentences\n",
    "n_words = len(words); \n",
    "print(\"Number of different words:\\t\" + str(n_words))\n",
    "\n",
    "#Count the tags\n",
    "tags = list(set(data[\"tag\"].values))\n",
    "n_tags = len(tags); \n",
    "print(\"Number of sentences:\\t\" + str(len(data.sentence.unique())))\n",
    "print(\"Number of different tags:\\t\" + str(n_tags))\n",
    "print(\"List of different tags:\\t\" + str(set(tags)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23b78b-ad4c-4ed4-880c-877b5b419173",
   "metadata": {},
   "source": [
    "### So we have 2394 sentences containing 9069 different words (considering also the specail tag ENDPAD) with 21 different tags. \n",
    "\n",
    "### We use the SentenceGetter class to retrieve sentences with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6965a158-6bb3-4d4e-9885-e10cfb812e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 0\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"].values.tolist(),\n",
    "                                                           s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"sentence\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            #s = self.grouped[\"sentence: {}\".format(self.n_sent)]\n",
    "            s = self.grouped[self.n_sent]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c159383f-6fa1-4fad-bfed-7f24963f92e4",
   "metadata": {},
   "source": [
    "### Sentences are loaded from the input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eab4729e-efd9-47f0-b278-bc6dc8e7d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first sentence is[('@sammielynnsmom', 'O'), ('@tg10781', 'O'), ('they', 'O'), ('will', 'O'), ('be', 'O'), ('all', 'O'), ('done', 'O'), ('by', 'O'), ('sunday', 'O'), ('trust', 'O'), ('me', 'O'), ('*wink*', 'O')]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Split sentences\n",
    "getter = SentenceGetter(data)\n",
    "#Get the first sentence\n",
    "sent = getter.get_next()\n",
    "print(\"The first sentence is\" + str(sent))\n",
    "\n",
    "#Load all sentences\n",
    "sentences = getter.sentences\n",
    "\n",
    "#Print the length distribution\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28537392-89bd-401b-b34c-2d6f3bfcb497",
   "metadata": {},
   "source": [
    "## Conveting Sentences and Tags into vectors\n",
    "\n",
    "### Sentences are converted into sequences of legth equal `max_len` (here 50). A **padding** is applied to shorter sentences. \n",
    "\n",
    "### Each word in the input dictiory is assigned to a number which will be later paired with a vector (randomly initialized). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d80c8e4-22f7-4aa2-9f65-46be52e43ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"chicago\" is assigned to  2092\n",
      "The tag \"B-gpe\" is assigned to 8\n",
      "\n",
      "Befor PADDING\n",
      "Original Sentence 1:\t[('@daraobriain', 'O'), ('hmmm', 'O'), ('.', 'O'), ('cant', 'O'), ('wait', 'O'), ('.', 'O'), ('comin', 'O'), ('on', 'O'), ('thursday', 'O'), ('.', 'O'), ('first', 'O'), ('time', 'O'), ('to', 'O'), ('the', 'B-facility'), ('apollo', 'I-facility'), ('.', 'O')]\n",
      "Numerical Representation 1:\t[2785, 3035, 9091, 19718, 13881, 9091, 16483, 2443, 20975, 9091, 1886, 18829, 8910, 2172, 10533, 9091]\n",
      "Length of Sentence 1:16\n",
      "The special word ENDPAD (used for padding) is assigned to:\t21551\n",
      "\n",
      "After PADDING\n",
      "Numerical Representation 1:\t[ 2785  3035  9091 19718 13881  9091 16483  2443 20975  9091  1886 18829\n",
      "  8910  2172 10533  9091 21934 21934 21934 21934 21934 21934 21934 21934\n",
      " 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934\n",
      " 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934\n",
      " 21934 21934]\n",
      "Length of Sentence 1:50\n"
     ]
    }
   ],
   "source": [
    "#Maximum length of the input sequences\n",
    "max_len = 50\n",
    "\n",
    "#Word and tags in the input word and tag dictionaries are numbered\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "print(\"The word \\\"chicago\\\" is assigned to  \" + str(word2idx[\"chicago\"]))\n",
    "print(\"The tag \\\"B-gpe\\\" is assigned to \" + str(tag2idx[\"B-geo-loc\"]))\n",
    "\n",
    "#Each sentence is converted into sequences of numbers, given the above dictionaries\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "\n",
    "print(\"\\nBefor PADDING\")\n",
    "print(\"Original Sentence 1:\\t\" + str(sentences[1]))\n",
    "print(\"Numerical Representation 1:\\t\" + str(X[1]))\n",
    "print(\"Length of Sentence 1:\" + str(len(X[1])))\n",
    "\n",
    "#APPLY PADDING\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words - 1)\n",
    "\n",
    "\n",
    "print(\"The special word ENDPAD (used for padding) is assigned to:\\t\" + str(word2idx[\"ENDPAD\"]))\n",
    "\n",
    "print(\"\\nAfter PADDING\")\n",
    "print(\"Numerical Representation 1:\\t\" + str(X[1]))\n",
    "print(\"Length of Sentence 1:\" + str(len(X[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a234ed0-d571-44be-90fa-19ec24eb5e70",
   "metadata": {},
   "source": [
    "### The output labels are converted into sequences as well, with a maximum legth equals to `max_len` (here 50). A **padding** is applied to shorter sentences, assigning to padded elements the  `O` label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f00cf4-82f4-4741-91cd-cca99045676e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After PADDING\n",
      "Output labels of 1:\t[7 7 7 7 7 7 7 7 7 7 7 7 7 3 0 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "Categorial Output labels for the first 10 tokens:\t[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Converting output labels into number and padding\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "\n",
    "print(\"\\nAfter PADDING\")\n",
    "print(\"Output labels of 1:\\t\" + str(y[1]))\n",
    "\n",
    "#Converting to categorial elements\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "\n",
    "print(\"Categorial Output labels for the first 10 tokens:\\t\" + str(y[1][0:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3499f7d1-3d34-4a10-8a9a-a968b1c4fff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train dataset:\t2154 sequences.\n",
      "Size of the test dataset:\t240 sequences.\n"
     ]
    }
   ],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "print(\"Size of the train dataset:\\t\" + str(len(X_tr))+ \" sequences.\")\n",
    "print(\"Size of the test dataset:\\t\" + str(len(X_te))+ \" sequences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de28118-4c8b-4a64-81ec-5b44805e8918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 50, 50)            1096750   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 50)            0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 50, 200)          120800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 50, 21)           4221      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,221,771\n",
      "Trainable params: 1,221,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "\n",
    "print(input)\n",
    "\n",
    "# The input (now sequences of numbers) are mapped into vectors of dimenaionality 50\n",
    "model = Embedding(input_dim=n_words, output_dim=50, input_length=max_len)(input)\n",
    "\n",
    "# A dropout to the ouput is applied\n",
    "model = Dropout(0.1)(model)\n",
    "\n",
    "# Bidirectional LSTM \n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "\n",
    "# A dense layer is defined to reduce the space to the same dimensionality of the output\n",
    "# A softmax is applied\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)  \n",
    "\n",
    "# The model is compiled \n",
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Print the summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06a093-2d23-4912-b70f-c892b1e63e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "61/61 [==============================] - 85s 1s/step - loss: 0.6332 - accuracy: 0.9650 - val_loss: 0.1918 - val_accuracy: 0.9746\n",
      "Epoch 2/5\n",
      "61/61 [==============================] - 65s 1s/step - loss: 0.1479 - accuracy: 0.9799 - val_loss: 0.1642 - val_accuracy: 0.9746\n",
      "Epoch 3/5\n",
      "61/61 [==============================] - 63s 1s/step - loss: 0.1279 - accuracy: 0.9799 - val_loss: 0.1551 - val_accuracy: 0.9746\n",
      "Epoch 4/5\n",
      "61/61 [==============================] - 64s 1s/step - loss: 0.1171 - accuracy: 0.9799 - val_loss: 0.1531 - val_accuracy: 0.9746\n",
      "Epoch 5/5\n",
      "61/61 [==============================] - 64s 1s/step - loss: 0.1047 - accuracy: 0.9799 - val_loss: 0.1483 - val_accuracy: 0.9746\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit(X_tr, np.array(y_tr), batch_size = batch_size, epochs = epochs, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35522f1-d1e3-4283-be83-820b2686b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c97ffc-db02-46e1-b912-b584dcede0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633234</td>\n",
       "      <td>0.965005</td>\n",
       "      <td>0.191772</td>\n",
       "      <td>0.97463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.147894</td>\n",
       "      <td>0.979876</td>\n",
       "      <td>0.164237</td>\n",
       "      <td>0.97463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.127946</td>\n",
       "      <td>0.979876</td>\n",
       "      <td>0.155108</td>\n",
       "      <td>0.97463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117096</td>\n",
       "      <td>0.979876</td>\n",
       "      <td>0.153139</td>\n",
       "      <td>0.97463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104707</td>\n",
       "      <td>0.979876</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>0.97463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.633234  0.965005  0.191772       0.97463\n",
       "1  0.147894  0.979876  0.164237       0.97463\n",
       "2  0.127946  0.979876  0.155108       0.97463\n",
       "3  0.117096  0.979876  0.153139       0.97463\n",
       "4  0.104707  0.979876  0.148269       0.97463"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea8a50-4375-4e05-8aea-ca6577ba7827",
   "metadata": {},
   "source": [
    "### The results on the Train/Validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19ca23-0d51-45dd-8fc1-7afbf3e25828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(hist[\"loss\"])\n",
    "plt.plot(hist[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b43c4e7-7568-4f67-8650-3e0b5e45cd49",
   "metadata": {},
   "source": [
    "### Evaluating on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6aabf6-52bb-4cbe-ae58-d13c62ff61c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first sentence is[('new', 'B-other'), ('orleans', 'I-other'), ('mother', 'I-other'), (\"'s\", 'I-other'), ('day', 'I-other'), ('parade', 'I-other'), ('shooting', 'O'), ('.', 'O'), ('one', 'O'), ('of', 'O'), ('the', 'O'), ('people', 'O'), ('hurt', 'O'), ('was', 'O'), ('a', 'O'), ('10-year-old', 'O'), ('girl', 'O'), ('.', 'O'), ('what', 'O'), ('the', 'O'), ('hell', 'O'), ('is', 'O'), ('wrong', 'O'), ('with', 'O'), ('people', 'O'), ('?', 'O')]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Split sentences\n",
    "getter = SentenceGetter(test_data)\n",
    "#Get the first sentence\n",
    "sent = getter.get_next()\n",
    "print(\"The first sentence is\" + str(sent))\n",
    "\n",
    "#Load all sentences\n",
    "sentences = getter.sentences\n",
    "\n",
    "#Print the length distribution\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef0784-246c-4627-b6be-ac69b0a1322c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After PADDING\n",
      "Numerical Representation 1:\t[ 6778 21152  3046   616 15629 17265  6904 19284 21934 21934 21934 21934\n",
      " 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934\n",
      " 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934\n",
      " 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934 21934\n",
      " 21934 21934]\n",
      "Length of Sentence 1:50\n"
     ]
    }
   ],
   "source": [
    "#Each sentence is converted into sequences of numbers, given the above dictionaries\n",
    "X_test = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "\n",
    "\n",
    "#APPLY PADDING\n",
    "X_test = pad_sequences(maxlen=max_len, sequences=X_test, padding=\"post\", value=n_words - 1)\n",
    "\n",
    "print(\"\\nAfter PADDING\")\n",
    "print(\"Numerical Representation 1:\\t\" + str(X_test[1]))\n",
    "print(\"Length of Sentence 1:\" + str(len(X_test[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a412105-35cf-4add-8409-d3c2bb7e5cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After PADDING\n",
      "Output labels of 1:\t[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "Categorial Output labels for the first 10 tokens:\t[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Converting output labels into number and padding\n",
    "y_test = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y_test = pad_sequences(maxlen=max_len, sequences=y_test, padding=\"post\", value=tag2idx[\"O\"])\n",
    "\n",
    "print(\"\\nAfter PADDING\")\n",
    "print(\"Output labels of 1:\\t\" + str(y_test[1]))\n",
    "\n",
    "#Converting to categorial elements\n",
    "y_test = [to_categorical(i, num_classes=n_tags) for i in y_test]\n",
    "\n",
    "print(\"Categorial Output labels for the first 10 tokens:\\t\" + str(y_test[1][0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a10a0-2889-482b-8c09-e0023fd44684",
   "metadata": {},
   "source": [
    "### Test data accuracy is 96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5daa84-dce9-446b-b802-b0c4d98cf21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 22s 183ms/step - loss: 0.1852 - accuracy: 0.9691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18521778285503387, 0.9690649509429932]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_test, y=np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640cd73a-2a28-4a3e-80f1-375f30bd67f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d643683e-3ecd-41c4-ad73-7a0f69cf5a51",
   "metadata": {},
   "source": [
    "# Ner using Transformer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11c0a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f30397a8-3691-41e2-9f2e-f03433be4bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "900eb536-b99c-46fc-956d-183a530144b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>@sammielynnsmom</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>@tg10781</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>they</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>will</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>be</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence             word tag\n",
       "0  sentence1  @sammielynnsmom   O\n",
       "1  sentence1         @tg10781   O\n",
       "2  sentence1             they   O\n",
       "3  sentence1             will   O\n",
       "4  sentence1               be   O"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b5088049-f399-4af9-962d-a88b38aa22b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentences</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>@sammielynnsmom</td>\n",
       "      <td>O</td>\n",
       "      <td>@sammielynnsmom @tg10781 they will be all done...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>@tg10781</td>\n",
       "      <td>O</td>\n",
       "      <td>@sammielynnsmom @tg10781 they will be all done...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>they</td>\n",
       "      <td>O</td>\n",
       "      <td>@sammielynnsmom @tg10781 they will be all done...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>will</td>\n",
       "      <td>O</td>\n",
       "      <td>@sammielynnsmom @tg10781 they will be all done...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence1</td>\n",
       "      <td>be</td>\n",
       "      <td>O</td>\n",
       "      <td>@sammielynnsmom @tg10781 they will be all done...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence             word tag  \\\n",
       "0  sentence1  @sammielynnsmom   O   \n",
       "1  sentence1         @tg10781   O   \n",
       "2  sentence1             they   O   \n",
       "3  sentence1             will   O   \n",
       "4  sentence1               be   O   \n",
       "\n",
       "                                           sentences              word_labels  \n",
       "0  @sammielynnsmom @tg10781 they will be all done...  O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "1  @sammielynnsmom @tg10781 they will be all done...  O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "2  @sammielynnsmom @tg10781 they will be all done...  O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "3  @sammielynnsmom @tg10781 they will be all done...  O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "4  @sammielynnsmom @tg10781 they will be all done...  O,O,O,O,O,O,O,O,O,O,O,O  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create a new column called \"sentence\" which groups the words by sentence \n",
    "data['sentences'] = data[['sentence','word','tag']].groupby(['sentence'])['word'].transform(lambda x: ' '.join(x))\n",
    "# let's also create a new column called \"word_labels\" which groups the tags by sentence \n",
    "data['word_labels'] = data[['sentence','word','tag']].groupby(['sentence'])['tag'].transform(lambda x: ','.join(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "abceb411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-geo-loc': 1,\n",
       " 'B-facility': 2,\n",
       " 'I-facility': 3,\n",
       " 'B-movie': 4,\n",
       " 'I-movie': 5,\n",
       " 'B-company': 6,\n",
       " 'B-product': 7,\n",
       " 'B-person': 8,\n",
       " 'B-other': 9,\n",
       " 'I-other': 10,\n",
       " 'B-sportsteam': 11,\n",
       " 'I-sportsteam': 12,\n",
       " 'I-product': 13,\n",
       " 'I-company': 14,\n",
       " 'I-person': 15,\n",
       " 'I-geo-loc': 16,\n",
       " 'B-tvshow': 17,\n",
       " 'B-musicartist': 18,\n",
       " 'I-musicartist': 19,\n",
       " 'I-tvshow': 20}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(data.tag.unique())}\n",
    "ids_to_labels = {v: k for v, k in enumerate(data.tag.unique())}\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ef4b3325-ccbc-4e20-881d-438401591140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@sammielynnsmom @tg10781 they will be all done...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>made it back home to ga . it sucks not to be a...</td>\n",
       "      <td>O,O,O,O,O,B-geo-loc,O,O,O,O,O,O,O,B-facility,I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>' breaking dawn ' returns to vancouver on janu...</td>\n",
       "      <td>O,B-movie,I-movie,O,O,O,B-geo-loc,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ls_n perhaps , but folks may find something i...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@carr0t aye been tonight - excellent</td>\n",
       "      <td>O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  @sammielynnsmom @tg10781 they will be all done...   \n",
       "1  made it back home to ga . it sucks not to be a...   \n",
       "2  ' breaking dawn ' returns to vancouver on janu...   \n",
       "3  @ls_n perhaps , but folks may find something i...   \n",
       "4               @carr0t aye been tonight - excellent   \n",
       "\n",
       "                                         word_labels  \n",
       "0                            O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "1  O,O,O,O,O,B-geo-loc,O,O,O,O,O,O,O,B-facility,I...  \n",
       "2          O,B-movie,I-movie,O,O,O,B-geo-loc,O,O,O,O  \n",
       "3  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "4                                        O,O,O,O,O,O  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[[\"sentences\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
    "data = data.rename(columns={'sentences': 'sentence'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d433a0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'man gets 20 years in murder plot against judge http://bit.ly/agb9il'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentence'][16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46313ea7-b237-4fc9-88f3-53f3c8f95009",
   "metadata": {},
   "source": [
    "#### **Preparing the dataset and dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13a8897b-2ae9-4fd7-92a6-df50480636f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2309"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "230c8eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is up and ready for his last day on the punt until stakes day ... #sadbuttrue'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[41].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0154fc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O,O,O,O,O,O,O,O,O,O,O,O,B-other,I-other,O,O'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[41].word_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1ca223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0b05d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "  def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels \n",
    "        sentence = self.data.sentence[index].strip().split()  \n",
    "        word_labels = self.data.word_labels[index].split(\",\") \n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        encoding = self.tokenizer(sentence,\n",
    "                             is_pretokenized=True, \n",
    "                             return_offsets_mapping=True, \n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)\n",
    "        \n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "        labels = [labels_to_ids[label] for label in word_labels] \n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        \n",
    "        # set only labels whose first offset position is 0 and the second is not 0\n",
    "        i = 0\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "          if mapping[0] == 0 and mapping[1] != 0:\n",
    "            # overwrite label\n",
    "            encoded_labels[idx] = labels[i]\n",
    "            i += 1\n",
    "\n",
    "        # step 4: turn everything into PyTorch tensors\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        \n",
    "        return item\n",
    "\n",
    "  def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "add85ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (2309, 2)\n",
      "TRAIN Dataset: (1847, 2)\n",
      "TEST Dataset: (462, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b5a77988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1030,  5977,  6834,  7106,  4931,  4086,  2100,  2031,  1037,\n",
       "          2307,  1010, 19613,  2051,  1024,  1007, 24459,  2000,  2017,   999,\n",
       "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'offset_mapping': tensor([[ 0,  0],\n",
       "         [ 0,  1],\n",
       "         [ 1,  5],\n",
       "         [ 5,  9],\n",
       "         [ 9, 13],\n",
       "         [ 0,  3],\n",
       "         [ 0,  5],\n",
       "         [ 5,  6],\n",
       "         [ 0,  4],\n",
       "         [ 0,  1],\n",
       "         [ 0,  5],\n",
       "         [ 0,  1],\n",
       "         [ 0,  8],\n",
       "         [ 0,  4],\n",
       "         [ 0,  1],\n",
       "         [ 1,  2],\n",
       "         [ 0,  4],\n",
       "         [ 0,  2],\n",
       "         [ 0,  3],\n",
       "         [ 0,  1],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0],\n",
       "         [ 0,  0]]),\n",
       " 'labels': tensor([-100,    0, -100, -100, -100,    0,    0, -100,    0,    0,    0,    0,\n",
       "            0,    0,    0, -100,    0,    0,    0,    0, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100], dtype=torch.int32)}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "98594002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]       -100\n",
      "@           0\n",
      "sean        -100\n",
      "##king      -100\n",
      "##ston      -100\n",
      "hey         0\n",
      "sweet       0\n",
      "##y         -100\n",
      "have        0\n",
      "a           0\n",
      "great       0\n",
      ",           0\n",
      "relaxing    0\n",
      "time        0\n",
      ":           0\n",
      ")           -100\n",
      "hugs        0\n",
      "to          0\n",
      "you         0\n",
      "!           0\n",
      "[SEP]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n",
    "  print('{0:10}  {1}'.format(token, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "67dd054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b932c220",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8c5c2f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=21, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e362bae",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c8663659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1377, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = training_set[2]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
    "labels = inputs[\"labels\"].unsqueeze(0).type(torch.LongTensor)\n",
    "\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "53a1b7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 21])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_logits = outputs[1]\n",
    "tr_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f6bbf0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1b0d5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_labels.extend(labels)\n",
    "        tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7963ff9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 100 training steps: 3.278249979019165\n",
      "Training loss per 100 training steps: 0.7497616786472868\n",
      "Training loss per 100 training steps: 0.5204234941311143\n",
      "Training loss per 100 training steps: 0.43569146185816326\n",
      "Training loss per 100 training steps: 0.3822518389653461\n",
      "Training loss epoch: 0.3562809706875224\n",
      "Training accuracy epoch: 0.9350354705862832\n",
      "Training epoch: 2\n",
      "Training loss per 100 training steps: 0.03478911146521568\n",
      "Training loss per 100 training steps: 0.18149742349465886\n",
      "Training loss per 100 training steps: 0.18351173949015526\n",
      "Training loss per 100 training steps: 0.17357036357658895\n",
      "Training loss per 100 training steps: 0.17097404987163414\n",
      "Training loss epoch: 0.1693438391203214\n",
      "Training accuracy epoch: 0.9606449911642804\n",
      "Training epoch: 3\n",
      "Training loss per 100 training steps: 0.0168474018573761\n",
      "Training loss per 100 training steps: 0.10517272519611634\n",
      "Training loss per 100 training steps: 0.10598049709800426\n",
      "Training loss per 100 training steps: 0.11676515062553096\n",
      "Training loss per 100 training steps: 0.1166842585200783\n",
      "Training loss epoch: 0.11439941647599625\n",
      "Training accuracy epoch: 0.9711699936463172\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624dd4f3",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cc80335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "            labels = batch['labels'].to(device, dtype = torch.long)\n",
    "            \n",
    "            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            \n",
    "            # only compute accuracy at active labels\n",
    "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        \n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(labels)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
    "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0b2acbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.0781094878911972\n",
      "Validation loss per 100 evaluation steps: 0.145653074996841\n",
      "Validation loss per 100 evaluation steps: 0.14578141751050466\n",
      "Validation Loss: 0.15153392643800803\n",
      "Validation Accuracy: 0.9621296346010356\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fc324e-a0b0-421f-b648-2057444d1361",
   "metadata": {},
   "source": [
    "### Training Accuracy: 97.11%\n",
    "### Validation Accuracy: 96.21%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb13fe5-77ce-493f-bbb8-515bcca98222",
   "metadata": {},
   "source": [
    "# Testing on custom input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dcb754ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G20', 'summit:', 'World', 'leaders', 'arrive', 'in', \"India's\", 'capital']\n",
      "['B-other', 'I-other', 'O', 'O', 'O', 'O', 'B-geo-loc', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"G20 summit: World leaders arrive in India's capital\"\n",
    "\n",
    "inputs = tokenizer(sentence.split(),\n",
    "                    is_pretokenized=True, \n",
    "                    return_offsets_mapping=True, \n",
    "                    padding='max_length', \n",
    "                    truncation=True, \n",
    "                    max_length=MAX_LEN,\n",
    "                    return_tensors=\"pt\")\n",
    "\n",
    "# move to gpu\n",
    "ids = inputs[\"input_ids\"].to(device)\n",
    "mask = inputs[\"attention_mask\"].to(device)\n",
    "# forward pass\n",
    "outputs = model(ids, attention_mask=mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "prediction = []\n",
    "for token_pred, mapping in zip(wp_preds, inputs[\"offset_mapping\"].squeeze().tolist()):\n",
    "  #only predictions on first word pieces are important\n",
    "  if mapping[0] == 0 and mapping[1] != 0:\n",
    "    prediction.append(token_pred[1])\n",
    "  else:\n",
    "    continue\n",
    "\n",
    "print(sentence.split())\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab103bb-5aaa-4ec3-adf0-f589bfae68cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
